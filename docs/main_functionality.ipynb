{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09685ab1-b68e-4599-999e-ee84aff026c9",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "The aim of this notebook is to elucidate the main backend functions that the frontend calls upon for important things shown to the user and dictated by the main computational modeling. In other words, this distills and presents the major backend functions and frontend locations, how they generally connect, and what they are supposed to do. This allows for focusing on the flow of the most important backend functionality as well as critical portions of relevant frontend pieces making those backend calls -- most likely, resolving existing issues and developing the app further will rely quite a bit on these places in the files discussed below.\n",
    "\n",
    "## FOCUS: \n",
    "\n",
    "The third screen the user sees - the dashboard with the passages (grouped by topic) that they use to create labels, and label the passage. The first screen is login, second screen is selecting preloaded dataset and specifying user settings (how-to on modifying what is contained in the settings that can be changed by the user including adding new ones, and also changing default values shown/used is documented in `customized_settings.md`, and the third screen is the dashboard - documents clustered by topic for labeling and also the app recommending the next doc/passage to label by highlighting with a red box and scrolling to that passage - this is THE dominant screen a user spends their time working with, and where the tool gets used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f1139-90e9-4959-a6c0-af83ce8f1dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "088b039f-1ace-4c08-8e7b-f3543d2306ca",
   "metadata": {},
   "source": [
    "## The main files: BACKEND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e64c8-c8a5-4cb6-a6d3-9ffdec7d2520",
   "metadata": {},
   "source": [
    "### annotation_session.py\n",
    "\n",
    "This file in app/backend/ is the most critical backend file, containing the major functions called upon during a user session. While supported by other files in the backend/ folder, this file defines the user settings, creates document groupings by topics, identifies the document the classifier is most uncertain about (for active-learning based recommendations), trains and updates the classifiers, and maintain the updated data texts, scores, labels, etc. Essentially, this is the file that contains the functions called upon by the frontend in most cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570128b7-d162-412a-8e66-8f398f7fff11",
   "metadata": {},
   "source": [
    "### server.py\n",
    "\n",
    "This file in app/backend/ is mostly there to coordinate calls from the frontend to the backend functions, and serves to tightly couple the frontend and backend. Frontend calls are routed through this, so substantial changes like addinng function in annotation_session.py might have to go through here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79094503-507f-49cd-bc6a-96623faf1699",
   "metadata": {},
   "source": [
    "## The main files: FRONTEND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2bd2-9c96-48bf-a803-1893a01a02a3",
   "metadata": {},
   "source": [
    "### src/Views/Dashboard.js\n",
    "\n",
    "This is the main file responsible for fetching what is needed to render the dashboard, most importantly, this fetches the document clusters (grouped by topic) and the next document to highlight from the backend (see refreshData()), and for then highlighting the chosen document and scrolling to it (in labelDocument()). \n",
    "\n",
    "### src/Components/DocumentsByTopic.jsx\n",
    "\n",
    "The above finally passes the document clusters and highlighted next document element, etc. to this file in order to actually render what the user sees for documents grouped by topic on the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377a130-cb44-45b7-8e8a-c24ab25653e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d72946-5a19-4d67-ace5-1b5b94761401",
   "metadata": {},
   "source": [
    "## CONNECTING THE MAIN FUNCTIONS: Which functions in the files above interact primarily to enable the functionality of the user dashboard used to create labels, and annotate: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bf75a-7bed-47eb-9e2c-2169bc88c09d",
   "metadata": {},
   "source": [
    "#### 1. Fetch the document clusters (group of the instances to label - grouped by their topic) and the next document to label per active learning paradigm (the document/instance the classifier is most uncertain about) -- FRONTEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a789ff-4a1a-4f9d-ab27-921db4fb18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABOVE is mainly done in src/Views/Dashboard.js in the refreshData() function in (line 67) [JAVASCRIPT CODE]\n",
    "\n",
    "async refreshData(sort_docs = 'uncertainty') {\n",
    "    console.log('refreshing data...');\n",
    "    this.setState({ isLoading: true });\n",
    "\n",
    "    const settings = await getRequest(`/get_settings`);\n",
    "    sort_docs = settings['sort_docs_by'];\n",
    "    const group_size = settings['num_top_docs_shown'];\n",
    "    console.log('sort_docs', sort_docs);\n",
    "\n",
    "    // the BELOW is where the main call to the backend made in order to get the document clusters and next doc to highlight!!\n",
    "    const res = await getRequest(`/get_document_clusters?group_size=${group_size}&sort_by=${sort_docs}`);\n",
    "    \n",
    "    // res is a dictionary containing document_clusters and doc_to_highlight; from the backend function get_document_clusters() in annotation_session.py\n",
    "\n",
    "    const docToHighlight = res['doc_to_highlight'];\n",
    "    console.log('docToHighlight', docToHighlight);\n",
    "    const document_clusters = res['document_clusters'];\n",
    "    console.log('document_clusters', document_clusters);\n",
    "\n",
    "    const labels = await getRequest(`/get_labels`);\n",
    "\n",
    "    const stats = await getRequest(`/get_statistics`);\n",
    "\n",
    "    const documents_grouped_by_label = await getRequest(`/get_documents_grouped_by_label`);\n",
    "\n",
    "    // below sets the data/groups and other info retrieved from backend for use throughout this javascript file in charge of creating the dashboard for the user\n",
    "    this.setState({\n",
    "        document_clusters: document_clusters,\n",
    "        labels: labels,\n",
    "        stats: stats,\n",
    "        documents_grouped_by_label: documents_grouped_by_label,\n",
    "        settings: settings,\n",
    "        docToHighlight: docToHighlight,\n",
    "        isLoading: false\n",
    "    });\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588a77a-e1c7-4558-b187-b1d6298b1e77",
   "metadata": {},
   "source": [
    "#### 2. Record what the user labels the current document shown as, and Highlight the next document they should label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee4d8a-cd20-4a27-b0a1-7f0a8de8d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABOVE is mainly done in src/Views/Dashboard.js in the labelDocument() function (line 153) [JAVASCRIPT CODE]\n",
    "\n",
    "// highlight next doc to label, scroll to it\n",
    "async labelDocument(doc_id, label) {\n",
    "    console.log('label doc:', doc_id, label);\n",
    "    console.log('doc element', document.getElementById(doc_id));\n",
    "    document.getElementById(doc_id).style.color = \"green\";\n",
    "    this.setState({ isLoading: true });\n",
    "    // force refresh page, not sure how to do this automatically\n",
    "    // this.forceUpdate();\n",
    "\n",
    "    //AN important backend function call made below to record the user label (and does other stuff), explained in cells below. \n",
    "    const resp = await postRequest(`/label_document?doc_id=${doc_id}&label=${label}`);\n",
    "    console.log('label doc response', resp);\n",
    "\n",
    "\n",
    "    // refresh the documents - CALLS THE FUNCTION ABOVE!\n",
    "    await this.refreshData();\n",
    "    // force refresh page, not sure how to do this automatically\n",
    "    // this.forceUpdate();\n",
    "\n",
    "    // the below can be simplified, if-else can be dropped since we want to highlight the next doc to label whether in active learning mode (3 docs labeled) or not! next doc should always be highlighted\n",
    "\n",
    "    // scroll to next doc to label, highlight (regardless of active learning status - in no active learning case, next doc chosen randomly)\n",
    "    if (resp['status'] === 'active_learning_update') {\n",
    "        // const next_doc = resp['next_doc_id_to_label'];\n",
    "        const next_doc = this.state.docToHighlight;\n",
    "        // console.log('next_doc', next_doc)\n",
    "\n",
    "        let element = document.getElementById(next_doc);\n",
    "        // highlight text, scroll to it\n",
    "        console.log('next element', element)\n",
    "        if (element !== null) {\n",
    "            element.style.border = \"thick solid red\";\n",
    "            element.scrollIntoView({ behavior: \"smooth\", block: \"center\" });\n",
    "            // remove border of previous element\n",
    "            if (this.state.highlightedDoc) {\n",
    "                this.state.highlightedDoc.style.borderColor = null;\n",
    "            }\n",
    "            this.setState({\n",
    "                highlightedDoc: element\n",
    "            });\n",
    "        } else {\n",
    "            console.log(\"couldn't find document!\");\n",
    "            // const first_doc = this.state.document_clusters[0]['documents'][0]['doc_id']\n",
    "            // element = document.getElementById(first_doc);\n",
    "            // console.log('next element', first_doc, element)\n",
    "            // if (element !== null) {\n",
    "            //     element.style.border = \"thick solid red\";\n",
    "            // element.scrollIntoView({behavior: \"smooth\", block: \"center\"});\n",
    "            // // remove border of previous element\n",
    "            // // this.state.highlightedDoc.style.borderColor = null;\n",
    "            // this.setState({\n",
    "            //     highlightedDoc: element\n",
    "            // });\n",
    "            // }\n",
    "        }\n",
    "    } else {\n",
    "        console.log('no active learning');\n",
    "        // const next_doc = resp['next_doc_id_to_label'];\n",
    "        const next_doc = this.state.docToHighlight;\n",
    "        // console.log('next_doc', next_doc)\n",
    "\n",
    "        let element = document.getElementById(next_doc);\n",
    "        // highlight text, scroll to it\n",
    "        console.log('next element', element)\n",
    "        if (element !== null) {\n",
    "            element.style.border = \"thick solid red\";\n",
    "            element.scrollIntoView({ behavior: \"smooth\", block: \"center\" });\n",
    "\n",
    "            // remove border of previous element\n",
    "            if (this.state.highlightedDoc) {\n",
    "                this.state.highlightedDoc.style.borderColor = null;\n",
    "            }   \n",
    "            this.setState({\n",
    "                highlightedDoc: element\n",
    "            });\n",
    "        } else {\n",
    "            console.log(\"couldn't find document!\");\n",
    "        }\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5391f6-1382-4d13-b5ba-922e1d8050d1",
   "metadata": {},
   "source": [
    "#### 3. (Backend) Create the documents clusters (groups of docs by topic) as well as get the active learning (uncertainty-score) based next document/passage/instance to recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54dae1-b62e-4a72-af49-c6c6d0ecd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above step primarily happens in backend/annotation_session.py in the get_document_clusters() function, line 184\n",
    "\n",
    "def get_document_clusters(self, group_size: int, sort_by: str):\n",
    "    '''\n",
    "    IMPORTANT FUNCTION (gets called on to get documents grouped by topics as well as the next document to highlight)\n",
    "\n",
    "    returns dict(document_clusters, doc_to_highlight)\n",
    "    document_clusters: documents clustered by their dominant topic\n",
    "    doc_to_highlight: id of the document to highlight, if any\n",
    "\n",
    "    group_size: number of docs per cluster\n",
    "    sort_by: uncertainty_score or prediction_score\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    columns = [\n",
    "        'doc_id',\n",
    "        'text',\n",
    "        'source',\n",
    "        'manual_label',\n",
    "        'predicted_label',\n",
    "        'prediction_score',\n",
    "        'uncertainty_score',\n",
    "        'previous_passage',\n",
    "        'next_passage',\n",
    "        'dominant_topic_percent',\n",
    "        ]\n",
    "\n",
    "    print('sort_by', sort_by)\n",
    "    if sort_by == 'uncertainty':\n",
    "        sort_by = 'uncertainty_score'\n",
    "    elif sort_by == 'confidence':\n",
    "        sort_by = 'prediction_score'\n",
    "\n",
    "    document_clusters = []\n",
    "    # print(self.document_data['dominant_topic'].head())\n",
    "    # groupby = self.document_data.groupby('dominant_topic_id')\n",
    "    # print(self.document_data)\n",
    "    # print(self.document_data['manual_label'].isnull())\n",
    "    '''\n",
    "    if self.settings['use_active_learning'] and self.get_num_labelled_docs() >= ACTIVE_LEARNER_MIN_DOCS: # active learning is active\n",
    "        groupby = self.document_data[self.document_data['manual_label'].isnull()].groupby('dominant_topic_id')\n",
    "        print('\\n --- ACTIVE LEARNING BLOCK OF GROUP BY --- \\n')\n",
    "    else:\n",
    "        groupby = self.document_data[self.document_data['manual_label'].isnull()].groupby('dominant_topic_id')\n",
    "        print('\\n --- NOT ACTIVE LEARNING BLOCK OF GROUP BY --- \\n')\n",
    "        # groupby = self.document_data.groupby('topic_model_prediction')\n",
    "    '''\n",
    "    groupby = self.document_data[self.document_data['manual_label'].isnull()].groupby('dominant_topic_id')\n",
    "\n",
    "    most_uncertain_docs = [] #this collects the top uncertain row of the dataframe for every group of docs, grouped by topic\n",
    "\n",
    "\n",
    "    # topic_labels = self.topic_model.lda_model.topic_label_dict\n",
    "    topic_labels = self.topic_model.label_set\n",
    "\n",
    "    print('topic labels:', topic_labels)\n",
    "    for topic_id, group in groupby:\n",
    "\n",
    "        # get the most uncertain documents\n",
    "        sorted_group = group.sort_values(sort_by, ascending=False)\n",
    "\n",
    "        '''\n",
    "        below uses num_top_docs_shown to show a specific number of top docs per topic to the user \n",
    "        if -1, it shows all docs in the topic group (grouped by dominant_topic_id above) instead of top most uncertain ones only\n",
    "        '''\n",
    "        if group_size == -1:\n",
    "            doc_ids = sorted_group['doc_id']\n",
    "        else:\n",
    "            doc_ids = sorted_group['doc_id'].head(group_size)\n",
    "\n",
    "        documents = self.document_data.iloc[doc_ids][columns].fillna('')\n",
    "\n",
    "        most_uncertain_docs.append(documents.head(1))\n",
    "\n",
    "        documents = documents.to_dict(orient='records')\n",
    "\n",
    "        # get the topic label, if any\n",
    "        topic_id = int(topic_id)\n",
    "        if topic_id < len(topic_labels):\n",
    "            topic_label = topic_labels[topic_id]\n",
    "        else:\n",
    "            topic_label = \"None\"\n",
    "\n",
    "        num_labelled_docs = int((group['manual_label'].notnull()).sum())\n",
    "        num_docs = int(group.shape[0])\n",
    "\n",
    "        document_clusters.append({\n",
    "            # 'topic_id': topic_id, \n",
    "            'topic_words': group.iloc[0]['topic_keywords'], \n",
    "            'documents': documents,\n",
    "            'topic_label': topic_label,\n",
    "            'num_labelled_docs': num_labelled_docs, \n",
    "            'num_docs': num_docs,\n",
    "            # how many docs in the group have actually been labelled? \n",
    "            })\n",
    "\n",
    "    # pick the next document that should be highlighted per the max of chosen score - it has to be one within the collected most uncertain doc in every topic group, so those rows are concantenated and top uncertain doc_id picked.\n",
    "    doc_to_highlight = int(pd.concat(most_uncertain_docs, 0).sort_values(sort_by, ascending=False).head(1)['doc_id']) #int(random.choice(most_uncertain_docs)['doc_id'])\n",
    "    print(type(self.document_data['uncertainty_score']))\n",
    "    print(self.document_data['uncertainty_score'].describe())\n",
    "    print('Doc to highlight = ' + str(doc_to_highlight))\n",
    "\n",
    "    #the below document clusters are used to organize the dashboard (see Dashboard.js) in frontend, and doc_to_highlight is the one that is supposed to be highlighted by the interface so user labels that.\n",
    "    return {'document_clusters': document_clusters, 'doc_to_highlight': doc_to_highlight}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753144c-0e46-4a01-b7ba-e36de561edbc",
   "metadata": {},
   "source": [
    "### 4. (Backend) After user hits submit on a label they created or used for the document, label that document on the backend, update models, update data with scores from the classifier (that are then used to recommend the next doc based on these scores in the function above). if batch finished: update classifier, retrain topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37bc90c-00e7-4a78-a7c5-40fab320760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABOVE is done in the annotation_session.py in the label_document() function [line 444]\n",
    "\n",
    "def label_document(self, doc_id, label, update_topic_model=True):\n",
    "    #another IMPORTANT FUNCTION!! This does get called in the all-important labelDocument function in Dashboard.js\n",
    "\n",
    "    self.status = 'processing...'\n",
    "    self.record_action('label_document', {'doc_id': doc_id, 'label': label})\n",
    "\n",
    "    if label not in self.labels:\n",
    "        self.labels.append(label)\n",
    "    self.document_data.loc[doc_id,'manual_label'] = label\n",
    "\n",
    "    # # topic model update logic - in batches determined by batch_update_freq (or number of labeling instances after which to update)\n",
    "    if update_topic_model and self.document_data['manual_label'].notnull().sum() % self.settings['batch_update_freq'] == 0: # retrain model\n",
    "        print('retraining topic model...')\n",
    "        # t = threading.Thread(target=train_topic_model, args=(self))\n",
    "        t = threading.Thread(target=self.train_topic_model)\n",
    "        t.start()\n",
    "        # self.train_topic_model()\n",
    "\n",
    "    # active learning logic\n",
    "    print('active learning logic...')\n",
    "    if self.settings['use_active_learning'] and self.get_num_labelled_docs() >= ACTIVE_LEARNER_MIN_DOCS: # active learning\n",
    "        #print('\\n --- ACTIVE LEARNING BEING USED BLOCK  --- \\n')\n",
    "        if not self.active_learner_started: # start active learning\n",
    "            print('\\n --- STARTING ACTIVE LEARNING  --- \\n')\n",
    "            df = self.document_data\n",
    "\n",
    "            self.initialize_classifier(df['text'], df['manual_label'])\n",
    "\n",
    "        else:\n",
    "            #print('\\n --- ACTIVE LEARNING: UPDATING CLASSIFIER  --- \\n')\n",
    "            print('updating classifier...')\n",
    "            self.status = 'updating classifier...'\n",
    "\n",
    "            query_idx = doc_id # doc id must equal query idx\n",
    "            self.learner.teach(self.corpus_features[query_idx], [label]) \n",
    "\n",
    "\n",
    "        # update model predictions -- IMPORTANT -- for actual active learning to happen.\n",
    "        self.update_document_metadata()\n",
    "\n",
    "        return \"active_learning_update\"\n",
    "    else:\n",
    "        return 'no_active_learning'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25411f50-8d9f-4e51-bf24-ca82d2ce0f57",
   "metadata": {},
   "source": [
    "## Broad overview of the app functionality with swimlane diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b5b56-d5f8-477a-b03a-8972361f04b7",
   "metadata": {},
   "source": [
    "![alt text](swimlane.drawio.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b881c5-d8a5-4441-a11a-9277926e53f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d4a6fd-d3b6-4338-a9cb-fdfa36052bae",
   "metadata": {},
   "source": [
    "## Question: Where is active learning primarily taking place in the code?\n",
    "\n",
    "Answer: Mainly in the backend file annotation_session.py; specifically look at code (also shown above) in the **label_document()** function. \n",
    "\n",
    "Once certain conditions are met - \n",
    "```\n",
    "if self.settings['use_active_learning'] and self.get_num_labelled_docs() >= ACTIVE_LEARNER_MIN_DOCS: \n",
    "```\n",
    "Active learning is either started for the first time by calling upon the initialize_classifier() function in the same file (which initialized the learner instance as well as sets `self.active_learner_started` to True)- \n",
    "```\n",
    "    #print('\\n --- ACTIVE LEARNING BEING USED BLOCK  --- \\n')\n",
    "    if not self.active_learner_started: # start active learning\n",
    "        print('\\n --- STARTING ACTIVE LEARNING  --- \\n')\n",
    "        df = self.document_data\n",
    "\n",
    "        self.initialize_classifier(df['text'], df['manual_label'])\n",
    "```\n",
    "OR if it had begun before, the label and document is passed to the teach functionality of the learner to simply update the classifier - \n",
    "\n",
    "```\n",
    "    else:\n",
    "        #print('\\n --- ACTIVE LEARNING: UPDATING CLASSIFIER  --- \\n')\n",
    "        print('updating classifier...')\n",
    "        self.status = 'updating classifier...'\n",
    "\n",
    "        query_idx = doc_id # doc id must equal query idx\n",
    "        self.learner.teach(self.corpus_features[query_idx], [label]) \n",
    "\n",
    "```\n",
    "\n",
    "And finally, the model predictions i.e. the scores are updated (so that the most uncertain doc can then be recommended by the app, etc.) - \n",
    "\n",
    "```\n",
    "    # update model predictions -- IMPORTANT -- for actual active learning to happen.\n",
    "    self.update_document_metadata()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4a49a-b8dc-4676-8c82-65d2406e2867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b568ca4-fb8f-4e46-931f-9ec7125c7387",
   "metadata": {},
   "source": [
    "## Question: How to swap out the existing topic modeling implementation for another one\n",
    "\n",
    "Answer: Topic modeling usage in the app is fairly modular. Create your own topic modeling py code file in the backend, say MY_topic_model.py; and import it in **annotation_session.py** (in place of the current import, see line 21). The main thing is to have all the existing function names that **topic_model_new.py** also has - you can make changes in terms of adding functions etc. but as long as you are using the same function names and have at least the functionality that currently exists, no other changes may need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af8522-02a0-4b23-a8e2-7bdd0dae0df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tbip] *",
   "language": "python",
   "name": "conda-env-tbip-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
